{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D, Convolution2D, Layer, UpSampling2D, Conv2DTranspose, Flatten, Reshape, Lambda, BatchNormalization,Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "inputShape = (128, 128, 3)\n",
    "latentSize = 64\n",
    "\n",
    "#encoder_type deepmind_enc\n",
    "data_dir = '/home/dovi/home/dataset'\n",
    "graph_dir = '/content/drive/My Drive/Colab Notebooks/VAE/graphs'\n",
    "test_image_folder = '/content/drive/My Drive/Colab Notebooks/VAE/test_images/celeb'\n",
    "encoder_type = 'deepmind_enc'\n",
    "save_dir = '/content/drive/My Drive/Colab Notebooks/VAE/saved_models'\n",
    "save_dir_img = '/content/drive/My Drive/Colab Notebooks/VAE/new_vae_images'\n",
    "val_split = 0.2\n",
    "\n",
    "train_batch_size = 64\n",
    "val_batch_size = 64 \n",
    "optimizer = 'ADAM' \n",
    "base_learning_rate = 0.01\n",
    "num_epochs = 100 \n",
    "scheduler_epoch = 5 \n",
    "decay_factor = 0.01 \n",
    "capacity = 25\n",
    "multi_process=True\n",
    "\n",
    "\n",
    "depth = 7\n",
    "nb_dense_block = 1\n",
    "growth_rate = 12\n",
    "nb_filter = 16\n",
    "dropout_rate=0.2\n",
    "weight_decay=1E-4\n",
    "latentConstraints='bvae', \n",
    "beta=10.\n",
    "training=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_output(generated_image):\n",
    "    generated_image[generated_image > 0.5] = 0.5\n",
    "    generated_image[generated_image < -0.5] = -0.5\n",
    "    gen_image = np.uint8((generated_image + 0.5) * 255)\n",
    "    return gen_image\n",
    "\n",
    "\n",
    "def batch_gen(generator_object):\n",
    "    while True:\n",
    "        data = generator_object.next()\n",
    "        yield [pre_process_input(data[0])], [pre_process_input(data[0])]\n",
    "      \n",
    "      \n",
    "def pre_process_input(image_array):\n",
    "    x = np.asarray(image_array)\n",
    "    y = x - 0.5\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLayer(Layer):\n",
    "    def __init__(self, gamma, capacity, slname, **kwargs):\n",
    "        super(SampleLayer, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.max_capacity = capacity\n",
    "        self.slname = slname\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SampleLayer, self).build(input_shape)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        if len(layer_inputs) != 2:\n",
    "            raise Exception('input layers must be a list: mean and stddev')\n",
    "        if len(K.int_shape(layer_inputs[0])) != 2 or len(K.int_shape(layer_inputs[1])) != 2:\n",
    "            raise Exception('input shape is not a vector [batchSize, latentSize]')\n",
    "\n",
    "        mean = layer_inputs[0]\n",
    "        log_var = layer_inputs[1]\n",
    "\n",
    "        batch = K.shape(mean)[0]\n",
    "        dim = K.int_shape(mean)[1]\n",
    "\n",
    "        latent_loss = -0.5 * (1 + log_var - K.square(mean) - K.exp(log_var))\n",
    "        latent_loss = K.sum(latent_loss, axis=1, keepdims=True)\n",
    "        latent_loss = K.mean(latent_loss)\n",
    "        latent_loss = self.gamma * K.abs(latent_loss - self.max_capacity)\n",
    "\n",
    "        latent_loss = K.reshape(latent_loss, [1, 1])\n",
    "\n",
    "        epsilon = K.random_normal(shape=(batch, dim), mean=0., stddev=1.)\n",
    "        layer_output = mean + K.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "        self.add_loss(losses=[latent_loss], inputs=[layer_inputs])\n",
    "\n",
    "        return layer_output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'gamma': self.gamma,\n",
    "            'capacity': self.max_capacity,\n",
    "            'name': self.slname\n",
    "        }\n",
    "        base_config = super(SampleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class Architecture(object):\n",
    "    '''\n",
    "    generic architecture template\n",
    "    '''\n",
    "    def __init__(self, inputShape=None, batchSize=None, latentSize=None):\n",
    "        '''\n",
    "        params:\n",
    "        ---------\n",
    "        inputShape : tuple\n",
    "            the shape of the input, expecting 3-dim images (h, w, 3)\n",
    "        batchSize : int\n",
    "            the number of samples in a batch\n",
    "        latentSize : int\n",
    "            the number of dimensions in the two output distribution vectors -\n",
    "            mean and std-deviation\n",
    "        latentSize : Bool or None\n",
    "            True forces resampling, False forces no resampling, None chooses based on K.learning_phase()\n",
    "        '''\n",
    "        self.inputShape = inputShape\n",
    "        self.batchSize = batchSize\n",
    "        self.latentSize = latentSize\n",
    "\n",
    "        self.model = self.Build()\n",
    "\n",
    "    def Build(self):\n",
    "        raise NotImplementedError('architecture must implement Build function')\n",
    "\n",
    "\n",
    "class Encoder(Architecture):\n",
    "\n",
    "    def __init__(self, input_shape=128, latent_dim=10):\n",
    "        self._input_shape = input_shape\n",
    "        self._z_dim = latent_dim\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_func(input_layer):\n",
    "        x = Conv2D(filters=32, kernel_size=4, strides=2, padding='same')(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build(self, vae_gamma, vae_capacity):\n",
    "        init = x = Input((self._input_shape, self._input_shape, 3))\n",
    "\n",
    "        for _ in range(5):\n",
    "            x = self.conv_func(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        x = Dense(units=256)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(units=256)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(units=self._z_dim * 2, activation='linear')(x)\n",
    "        # Beta-VAE implementation as follows\n",
    "\n",
    "        z_mean = Dense(units=self._z_dim, activation='linear', name='sample_mean')(x)\n",
    "        z_log_var = Dense(units=self._z_dim, activation='linear', name='sample_log_var')(x)\n",
    "        embed_layer = SampleLayer(gamma=vae_gamma, capacity=vae_capacity, slname='sampling_layer')([z_mean, \n",
    "                                                                                                    z_log_var])\n",
    "\n",
    "        return init, embed_layer\n",
    "\n",
    "    def create_encoder(self, vae_gamma, vae_capacity):\n",
    "        init, embed_layer = self.build(vae_gamma=vae_gamma, vae_capacity=vae_capacity)\n",
    "        model = Model(inputs=[init], outputs=[embed_layer])\n",
    "        return init, model\n",
    "\n",
    "\n",
    "class Decoder(Architecture):\n",
    "    def __init__(self, decoder_input, latent_dim, output_shape):\n",
    "        self._dec_input = decoder_input\n",
    "        self._latent_dim = latent_dim\n",
    "\n",
    "    @staticmethod\n",
    "    def deconv_func(input_layer, pad_mode='same'):\n",
    "        x = Conv2DTranspose(32, 4, strides=2, padding=pad_mode)(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build(self, encoder_output):\n",
    "        x = Dense(units=256)(encoder_output)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(units=256)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(units=512, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Reshape((-1, 1, 512), input_shape=(512,))(x)\n",
    "\n",
    "        for i in range(5):\n",
    "            if i == 0:\n",
    "                x = self.deconv_func(x, pad_mode='valid')\n",
    "            else:\n",
    "                x = self.deconv_func(x)\n",
    "        x = Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)\n",
    "        decoded = x\n",
    "        return decoded\n",
    "\n",
    "    def create_decoder(self):\n",
    "        input_dec = Lambda(lambda x: x, name='decoder_inp')(self._dec_input)\n",
    "\n",
    "        return self.build(encoder_output=input_dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "import time\n",
    "\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=decay_factor, mode='min', patience=scheduler_epoch, min_lr=1e-010)\n",
    "timestamp = time.strftime(\"%d%m%Y\", time.localtime())\n",
    "\n",
    "save_file = os.path.join(save_dir, str(encoder_type + '_vae' + timestamp + '.hdf5'))\n",
    "checkpoint = ModelCheckpoint(filepath=save_file, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_output(generated_image):\n",
    "    generated_image[generated_image > 0.5] = 0.5\n",
    "    generated_image[generated_image < -0.5] = -0.5\n",
    "    gen_image = np.uint8((generated_image + 0.5) * 255)\n",
    "    return gen_image\n",
    "\n",
    "\n",
    "def batch_gen(generator_object):\n",
    "    while True:\n",
    "        data = generator_object.next()\n",
    "        yield [pre_process_input(data[0])], [pre_process_input(data[0])]\n",
    "      \n",
    "      \n",
    "def pre_process_input(image_array):\n",
    "    x = np.asarray(image_array)\n",
    "    y = x - 0.5\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191197 images belonging to 1 classes.\n",
      "Found 47799 images belonging to 1 classes.\n",
      "Steps per epoch in training:  2988\n",
      "Steps per epoch in validation:  747\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1 / 255.,validation_split=val_split)\n",
    "\n",
    "train_generator = data_gen.flow_from_directory(data_dir, target_size=(image_size, image_size), batch_size=train_batch_size, class_mode='categorical', subset='training')\n",
    "\n",
    "validation_generator = data_gen.flow_from_directory(data_dir, target_size=(image_size, image_size), batch_size=val_batch_size, class_mode='categorical', subset='validation')\n",
    "\n",
    "training_steps = math.ceil(train_generator.n / train_batch_size)\n",
    "validation_steps = math.ceil(validation_generator.n / val_batch_size)\n",
    "\n",
    "print('Steps per epoch in training: ', training_steps)\n",
    "print('Steps per epoch in validation: ', validation_steps)\n",
    "\n",
    "training_generator = batch_gen(generator_object=train_generator)\n",
    "\n",
    "validation_generator = batch_gen(generator_object=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 32)   1568        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   16416       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 32)   16416       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 32)     16416       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 32)     128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 32)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 32)     16416       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 32)     128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4, 4, 32)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sample_mean (Dense)             (None, 64)           8256        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sample_log_var (Dense)          (None, 64)           8256        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sample_layer (SampleLayer)      (None, 64)           0           sample_mean[0][0]                \n",
      "                                                                 sample_log_var[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inp (Lambda)            (None, 64)           0           sample_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          16640       decoder_inp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          131584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 512)          2048        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, None, 1, 512) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, None, 4, 32)  262176      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 4, 32)  128         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 4, 32)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, None, 8, 32)  16416       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, 8, 32)  128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 8, 32)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, None, 16, 32) 16416       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, 16, 32) 128         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 16, 32) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, None, 32, 32) 16416       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 32, 32) 128         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, 32, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, None, 64, 32) 16416       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 64, 32) 128         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, 64, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, None, 128, 3) 1539        activation_13[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 864,579\n",
      "Trainable params: 860,867\n",
      "Non-trainable params: 3,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# This is how you build the autoencoder\n",
    "enc = Encoder(input_shape=image_size, latent_dim=latentSize)\n",
    "enc_input, enc_model = enc.create_encoder(vae_gamma=10, vae_capacity=0)\n",
    "z = enc_model.output\n",
    "dec = Decoder(decoder_input=z, latent_dim=latentSize, output_shape=image_size)\n",
    "dec_output = dec.create_decoder()\n",
    "\n",
    "model = Model(inputs=[enc_input], outputs=[dec_output])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2988/2988 [==============================] - 1216s 407ms/step - loss: 1.0248 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "2988/2988 [==============================] - 1626s 544ms/step - loss: 0.0303 - val_loss: 0.0199\n",
      "Epoch 3/100\n",
      "2988/2988 [==============================] - 1606s 537ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 4/100\n",
      "2988/2988 [==============================] - 1689s 565ms/step - loss: 0.0187 - val_loss: 0.0459\n",
      "Epoch 5/100\n",
      "2988/2988 [==============================] - 1337s 448ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 6/100\n",
      "2988/2988 [==============================] - 1235s 413ms/step - loss: 0.0279 - val_loss: 0.0160\n",
      "Epoch 7/100\n",
      "2988/2988 [==============================] - 1220s 408ms/step - loss: 0.0159 - val_loss: 0.0162\n",
      "Epoch 8/100\n",
      " 228/2988 [=>............................] - ETA: 14:57 - loss: 0.0159"
     ]
    }
   ],
   "source": [
    "model.fit_generator(training_generator, steps_per_epoch=training_steps, epochs=num_epochs,\n",
    "                validation_data=validation_generator,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('deepMV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('deepMV.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_vae_loss(y_true, y_pred):\n",
    "    xent_loss = image_size * image_size * mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    kl_loss = - 0.5 * beta * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='rmsprop', loss=my_vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 64), (None, 64),  316448    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, None, 128, 3)      548131    \n",
      "=================================================================\n",
      "Total params: 864,579\n",
      "Trainable params: 860,867\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'sample_mean/kernel:0', 'sample_mean/bias:0', 'sample_log_var/kernel:0', 'sample_log_var/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_transpose_4/kernel:0', 'conv2d_transpose_4/bias:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_transpose_5/kernel:0', 'conv2d_transpose_5/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-426af13486d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization_5/gamma:0', 'batch_normalization_5/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_6/gamma:0', 'batch_normalization_6/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'sample_mean/kernel:0', 'sample_mean/bias:0', 'sample_log_var/kernel:0', 'sample_log_var/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'batch_normalization_7/gamma:0', 'batch_normalization_7/beta:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'batch_normalization_8/gamma:0', 'batch_normalization_8/beta:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'batch_normalization_9/gamma:0', 'batch_normalization_9/beta:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'batch_normalization_10/gamma:0', 'batch_normalization_10/beta:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'batch_normalization_11/gamma:0', 'batch_normalization_11/beta:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'batch_normalization_12/gamma:0', 'batch_normalization_12/beta:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'batch_normalization_13/gamma:0', 'batch_normalization_13/beta:0', 'conv2d_transpose_4/kernel:0', 'conv2d_transpose_4/bias:0', 'batch_normalization_14/gamma:0', 'batch_normalization_14/beta:0', 'conv2d_transpose_5/kernel:0', 'conv2d_transpose_5/bias:0']."
     ]
    }
   ],
   "source": [
    "vae.fit_generator(training_generator, steps_per_epoch=training_steps, epochs=num_epochs,validation_data=validation_generator,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0ca82b29604d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     39\u001b[0m   return [\n\u001b[1;32m     40\u001b[0m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   ]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mlist_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mListDevicesWithSessionConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2202\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a1fbdea29eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = Session(config = config)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
